/**
 * Self-Attention (è‡ªæ³¨æ„åŠ›æœºåˆ¶) CUDA å®ç°
 *
 * è‡ªæ³¨æ„åŠ›æœºåˆ¶æ˜¯ Transformer
 * æ¶æ„çš„æ ¸å¿ƒç»„ä»¶ï¼Œç”¨äºè®¡ç®—åºåˆ—ä¸­æ¯ä¸ªä½ç½®ä¸å…¶ä»–æ‰€æœ‰ä½ç½®çš„å…³ç³»ã€‚
 *
 * æ ¸å¿ƒå…¬å¼ï¼š
 * ==========
 * Attention(Q, K, V) = softmax(QK^T / âˆšd_k) V
 *
 * å…¶ä¸­ï¼š
 *   - Q: Query çŸ©é˜µï¼Œå½¢çŠ¶ [m, n]
 *     * m: åºåˆ—é•¿åº¦ï¼ˆtoken æ•°é‡ï¼‰
 *     * n: ç‰¹å¾ç»´åº¦ï¼ˆd_kï¼Œå³ key çš„ç»´åº¦ï¼‰
 *   - K: Key çŸ©é˜µï¼Œå½¢çŠ¶ [m, n]
 *   - V: Value çŸ©é˜µï¼Œå½¢çŠ¶ [m, n]
 *   - O: è¾“å‡ºçŸ©é˜µï¼Œå½¢çŠ¶ [m, n]
 *
 * è®¡ç®—æ­¥éª¤ï¼š
 * ==========
 * 1. è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ï¼šS = QK^T
 *    - å½¢çŠ¶ï¼šQ [m, n] Ã— K^T [n, m] â†’ S [m, m]
 *    - S[i, j] è¡¨ç¤ºç¬¬ i ä¸ª token å¯¹ç¬¬ j ä¸ª token çš„æ³¨æ„åŠ›åˆ†æ•°
 *
 * 2. ç¼©æ”¾ï¼ˆScaleï¼‰ï¼šS_scaled = S / âˆšn
 *    - é™¤ä»¥ âˆšd_k é˜²æ­¢ç‚¹ç§¯å€¼è¿‡å¤§å¯¼è‡´ softmax æ¢¯åº¦æ¶ˆå¤±
 *    - ç¼©æ”¾å› å­ï¼š1 / âˆšn
 *
 * 3. Softmax å½’ä¸€åŒ–ï¼šP = softmax(S_scaled)
 *    - å¯¹æ¯ä¸€è¡Œè¿›è¡Œ softmaxï¼Œä½¿å¾—æ¯è¡Œå’Œä¸º 1
 *    - å…¬å¼ï¼šP[i, j] = exp(S_scaled[i, j]) / Î£_k exp(S_scaled[i, k])
 *    - å½¢çŠ¶ï¼šP [m, m]
 *
 * 4. åŠ æƒæ±‚å’Œï¼šO = PV
 *    - å½¢çŠ¶ï¼šP [m, m] Ã— V [m, n] â†’ O [m, n]
 *    - O[i, :] = Î£_j P[i, j] * V[j, :]
 *
 * çŸ©é˜µç»´åº¦è¯´æ˜ï¼š
 * ==============
 * - Q, K, V: [m, n] - m ä¸ª tokenï¼Œæ¯ä¸ª token æœ‰ n ç»´ç‰¹å¾
 * - QK^T: [m, m] - æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ
 * - softmax(QK^T / âˆšn): [m, m] - æ³¨æ„åŠ›æƒé‡çŸ©é˜µï¼ˆæ¯è¡Œå’Œä¸º 1ï¼‰
 * - O: [m, n] - è¾“å‡ºçŸ©é˜µ
 *
 * å®ç°ç»†èŠ‚ï¼š
 * ==========
 * - ä½¿ç”¨ naive GEMMï¼ˆé€šç”¨çŸ©é˜µä¹˜æ³•ï¼‰å®ç°çŸ©é˜µä¹˜æ³•
 * - ä½¿ç”¨è¡Œçº§ softmax å¯¹æ¯è¡Œè¿›è¡Œå½’ä¸€åŒ–
 * - ä½¿ç”¨ mBlock å‚æ•°æ§åˆ¶æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„è¡Œæ•°
 */

// main.cu
#include <assert.h>
#include <cuda_runtime.h>
#include <stdio.h>

#include <cmath>
#include <fstream>
#include <iostream>

#include "helper.h"

#define CUDA_CHECK(condition)                                          \
  do {                                                                 \
    cudaError_t error = condition;                                     \
    if (error != cudaSuccess) {                                        \
      printf("CUDA_CHECK error in line %d of file %s: %s\n", __LINE__, \
             __FILE__, cudaGetErrorString(cudaGetLastError()));        \
      exit(EXIT_FAILURE);                                              \
    }                                                                  \
  } while (0)

// #define DEBUG

#ifdef DEBUG
#define DEBUG_BLOCK(expr) \
  do {                    \
    expr                  \
  } while (0)
#else
#define DEBUG_BLOCK(...) \
  do {                   \
  } while (0)
#endif

// -------------------------------
// CUDA Kernels
// -------------------------------

/**
 * Naive é€šç”¨çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰kernelï¼ŒæŒ‰è¡Œåˆ†å—
 *
 * è®¡ç®—ï¼šC = a * (A Ã— B^T) + b * C
 *
 * çŸ©é˜µç»´åº¦ï¼š
 *   - A: [M, K] - å·¦çŸ©é˜µ
 *   - B: [N, K] - å³çŸ©é˜µï¼ˆæ³¨æ„ï¼šå®é™…è®¡ç®— A Ã— B^Tï¼‰
 *   - C: [M, N] - è¾“å‡ºçŸ©é˜µ
 *
 * è®¡ç®—å…¬å¼ï¼š
 *   C[i, j] = a * Î£_k (A[i, k] * B[j, k]) + b * C[i, j]
 *            = a * (A[i, :] Â· B[j, :]) + b * C[i, j]
 *
 * å…¶ä¸­ï¼š
 *   - A[i, k] * B[j, k] è¡¨ç¤º A çš„ç¬¬ i è¡Œä¸ B çš„ç¬¬ j è¡Œçš„ç‚¹ç§¯
 *   - è¿™ç­‰ä»·äºè®¡ç®— A Ã— B^Tï¼Œå› ä¸º (B^T)[k, j] = B[j, k]
 *
 * å¹¶è¡ŒåŒ–ç­–ç•¥ï¼š
 *   - æ¯ä¸ªçº¿ç¨‹å¤„ç† mBlock è¡Œ
 *   - çº¿ç¨‹ç´¢å¼•è®¡ç®—ï¼šidx = (threadIdx.x + blockDim.x * blockIdx.x) * mBlock
 *   - çº¿ç¨‹ i å¤„ç†è¡Œ [idx, idx + mBlock)
 *
 * @param A è¾“å…¥çŸ©é˜µ Aï¼Œå½¢çŠ¶ [M, K]ï¼Œè¡Œä¸»åºå­˜å‚¨
 * @param B è¾“å…¥çŸ©é˜µ Bï¼Œå½¢çŠ¶ [N, K]ï¼Œè¡Œä¸»åºå­˜å‚¨ï¼ˆå®é™…è®¡ç®— B^Tï¼‰
 * @param C è¾“å‡ºçŸ©é˜µ Cï¼Œå½¢çŠ¶ [M, N]ï¼Œè¡Œä¸»åºå­˜å‚¨
 * @param a ç¼©æ”¾å› å­ï¼Œç”¨äºç¼©æ”¾çŸ©é˜µä¹˜æ³•çš„ç»“æœ
 * @param b ç¼©æ”¾å› å­ï¼Œç”¨äºç¼©æ”¾ C çš„åŸå§‹å€¼ï¼ˆç”¨äºç´¯åŠ æ“ä½œï¼‰
 * @param M A å’Œ C çš„è¡Œæ•°
 * @param N B çš„åˆ—æ•°å’Œ C çš„åˆ—æ•°
 * @param K A çš„åˆ—æ•°å’Œ B çš„è¡Œæ•°ï¼ˆå†…ç§¯ç»´åº¦ï¼‰
 * @param mBlock æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„è¡Œæ•°ï¼ˆblock sizeï¼‰
 *
 * åœ¨è‡ªæ³¨æ„åŠ›ä¸­çš„åº”ç”¨ï¼š
 *   - è®¡ç®— QK^Tï¼šA=Q [m, n], B=K [m, n], ç»“æœ C [m, m]
 *   - ç¼©æ”¾å› å­ a = 1/âˆšnï¼ˆç¼©æ”¾æ³¨æ„åŠ›åˆ†æ•°ï¼‰
 *   - ç¼©æ”¾å› å­ b = 0ï¼ˆä¸ç´¯åŠ ï¼Œç›´æ¥è¦†ç›–ï¼‰
 */
__global__ void naive_nrow_gemm(float *A, float *B, float *C, float a, float b,
                                int M, int N, int K, int mBlock) {
  // è®¡ç®—çº¿ç¨‹çš„èµ·å§‹è¡Œç´¢å¼•
  // æ¯ä¸ªçº¿ç¨‹å¤„ç† mBlock è¡Œï¼Œæé«˜å†…å­˜è®¿é—®æ•ˆç‡
  int idx = threadIdx.x + blockDim.x * blockIdx.x;
  idx *= mBlock;

  // æ¯ä¸ªçº¿ç¨‹å¤„ç† mBlock è¡Œ
  for (int i = idx; i < idx + mBlock; i++) {
    // å¯¹æ¯ä¸€è¡Œï¼Œè®¡ç®—ä¸ B çš„æ‰€æœ‰è¡Œçš„ç‚¹ç§¯
    for (int j = 0; j < N; j++) {
      float sum = 0.f;
      // è®¡ç®— A[i, :] ä¸ B[j, :] çš„ç‚¹ç§¯
      // è¿™ç­‰ä»·äº (A Ã— B^T)[i, j]
      for (int k = 0; k < K; k++) {
        sum += A[i * K + k] * B[j * K + k];  // A[i, k] * B[j, k]
      }
      // C[i, j] = a * sum + b * C[i, j]
      // å½“ a=1/âˆšn, b=0 æ—¶ï¼šC[i, j] = (QK^T)[i, j] / âˆšn
      C[i * N + j] = a * sum + b * C[i * N + j];
    }
  }
}

/**
 * Naive çŸ©é˜µä¹˜æ³• kernelï¼šè®¡ç®— O = P Ã— V
 *
 * åœ¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œç”¨äºè®¡ç®—æœ€ç»ˆè¾“å‡ºï¼š
 *   O = softmax(QK^T / âˆšn) Ã— V
 *
 * çŸ©é˜µç»´åº¦ï¼š
 *   - P: [M, M] - æ³¨æ„åŠ›æƒé‡çŸ©é˜µï¼ˆsoftmax åçš„ç»“æœï¼‰
 *   - V: [M, N] - Value çŸ©é˜µ
 *   - O: [M, N] - è¾“å‡ºçŸ©é˜µ
 *
 * è®¡ç®—å…¬å¼ï¼š
 *   O[i, j] = Î£_k (P[i, k] * V[k, j])
 *            = P[i, :] Â· V[:, j]
 *
 * ç‰©ç†æ„ä¹‰ï¼š
 *   - P[i, k] è¡¨ç¤ºç¬¬ i ä¸ª token å¯¹ç¬¬ k ä¸ª token çš„æ³¨æ„åŠ›æƒé‡
 *   - O[i, j] æ˜¯ç¬¬ i ä¸ª token çš„è¾“å‡ºï¼Œæ˜¯æ‰€æœ‰ token çš„ Value å‘é‡çš„åŠ æƒå’Œ
 *   - æƒé‡ç”±æ³¨æ„åŠ›çŸ©é˜µ P çš„ç¬¬ i è¡Œå†³å®š
 *
 * å¹¶è¡ŒåŒ–ç­–ç•¥ï¼š
 *   - æ¯ä¸ªçº¿ç¨‹å¤„ç† mBlock è¡Œ
 *   - çº¿ç¨‹ç´¢å¼•è®¡ç®—ï¼šidx = (threadIdx.x + blockDim.x * blockIdx.x) * mBlock
 *
 * @param P æ³¨æ„åŠ›æƒé‡çŸ©é˜µï¼Œå½¢çŠ¶ [M, M]ï¼Œè¡Œä¸»åºå­˜å‚¨
 *          - P[i, j] è¡¨ç¤ºç¬¬ i ä¸ª token å¯¹ç¬¬ j ä¸ª token çš„æ³¨æ„åŠ›æƒé‡
 *          - æ¯è¡Œå’Œä¸º 1ï¼ˆç»è¿‡ softmax å½’ä¸€åŒ–ï¼‰
 * @param V Value çŸ©é˜µï¼Œå½¢çŠ¶ [M, N]ï¼Œè¡Œä¸»åºå­˜å‚¨
 *          - V[i, :] è¡¨ç¤ºç¬¬ i ä¸ª token çš„ Value å‘é‡
 * @param O è¾“å‡ºçŸ©é˜µï¼Œå½¢çŠ¶ [M, N]ï¼Œè¡Œä¸»åºå­˜å‚¨
 *          - O[i, :] è¡¨ç¤ºç¬¬ i ä¸ª token çš„è¾“å‡ºå‘é‡
 * @param M P çš„è¡Œæ•°ï¼Œä¹Ÿæ˜¯ V çš„è¡Œæ•°ï¼Œç­‰äºåºåˆ—é•¿åº¦ m
 * @param N V çš„åˆ—æ•°å’Œ O çš„åˆ—æ•°ï¼Œç­‰äºç‰¹å¾ç»´åº¦ n
 * @param mBlock æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„è¡Œæ•°ï¼ˆblock sizeï¼‰
 */
__global__ void naive_pv(float *P, float *V, float *O, int M, int N,
                         int mBlock) {
  // è®¡ç®—çº¿ç¨‹çš„èµ·å§‹è¡Œç´¢å¼•
  int idx = threadIdx.x + blockDim.x * blockIdx.x;
  idx *= mBlock;

  int K = M;  // P çš„åˆ—æ•° = V çš„è¡Œæ•° = Mï¼ˆåºåˆ—é•¿åº¦ï¼‰

  // æ¯ä¸ªçº¿ç¨‹å¤„ç† mBlock è¡Œ
  for (int i = idx; i < idx + mBlock; i++) {
    // å¯¹æ¯ä¸€è¡Œï¼Œè®¡ç®—ä¸ V çš„çŸ©é˜µä¹˜æ³•
    for (int j = 0; j < N; j++) {
      float sum = 0.f;
      // è®¡ç®— O[i, j] = Î£_k P[i, k] * V[k, j]
      // è¿™æ˜¯ P çš„ç¬¬ i è¡Œä¸ V çš„ç¬¬ j åˆ—çš„ç‚¹ç§¯
      for (int k = 0; k < K; k++) {
        sum += P[i * K + k] * V[k * N + j];  // P[i, k] * V[k, j]
      }
      O[i * N + j] = sum;  // O[i, j] = Î£_k P[i, k] * V[k, j]
    }
  }
}

/**
 * è¡Œçº§ Softmax kernel
 *
 * å¯¹è¾“å…¥çŸ©é˜µçš„æ¯ä¸€è¡Œè¿›è¡Œ softmax å½’ä¸€åŒ–ï¼Œä½¿å¾—æ¯è¡Œå…ƒç´ å’Œä¸º 1ã€‚
 *
 * Softmax å…¬å¼ï¼š
 *   softmax(x_i) = exp(x_i - max(x)) / Î£_j exp(x_j - max(x))
 *
 * æ•°å€¼ç¨³å®šæ€§ä¼˜åŒ–ï¼š
 *   - ä½¿ç”¨ max_val å‡å»æ¯è¡Œæœ€å¤§å€¼ï¼Œé˜²æ­¢ exp æº¢å‡º
 *   - å…¬å¼ï¼šexp(x_i - max(x)) è€Œä¸æ˜¯ exp(x_i)
 *
 * è®¡ç®—æ­¥éª¤ï¼š
 *   1. æ‰¾åˆ°æ¯è¡Œçš„æœ€å¤§å€¼ max_val
 *   2. è®¡ç®— exp(x_i - max_val) å¹¶ç´¯åŠ å¾—åˆ° sum
 *   3. å½’ä¸€åŒ–ï¼šæ¯ä¸ªå…ƒç´ é™¤ä»¥ sum
 *
 * åœ¨è‡ªæ³¨æ„åŠ›ä¸­çš„åº”ç”¨ï¼š
 *   - è¾“å…¥ï¼šæ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ S [m, m] = QK^T / âˆšn
 *   - è¾“å‡ºï¼šæ³¨æ„åŠ›æƒé‡çŸ©é˜µ P [m, m]ï¼Œæ¯è¡Œå’Œä¸º 1
 *   - P[i, j] = exp(S[i, j] - max_k S[i, k]) / Î£_k exp(S[i, k] - max_k S[i, k])
 *
 * å¹¶è¡ŒåŒ–ç­–ç•¥ï¼š
 *   - æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€è¡Œ
 *   - çº¿ç¨‹ idx å¤„ç†ç¬¬ idx è¡Œ
 *
 * @param input è¾“å…¥çŸ©é˜µï¼Œå½¢çŠ¶ [rows, n]ï¼Œè¡Œä¸»åºå­˜å‚¨
 *              - åœ¨è‡ªæ³¨æ„åŠ›ä¸­ï¼šinput æ˜¯ç¼©æ”¾åçš„æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ [m, m]
 * @param output è¾“å‡ºçŸ©é˜µï¼Œå½¢çŠ¶ [rows, n]ï¼Œè¡Œä¸»åºå­˜å‚¨
 *               - åœ¨è‡ªæ³¨æ„åŠ›ä¸­ï¼šoutput æ˜¯æ³¨æ„åŠ›æƒé‡çŸ©é˜µ [m, m]
 *               - æ¯è¡Œå…ƒç´ å’Œä¸º 1
 * @param n æ¯è¡Œçš„å…ƒç´ æ•°é‡ï¼ˆåˆ—æ•°ï¼‰
 *          - åœ¨è‡ªæ³¨æ„åŠ›ä¸­ï¼šn = mï¼ˆåºåˆ—é•¿åº¦ï¼‰
 */
__global__ void row_softmax(float *input, float *output, int n) {
  // è®¡ç®—å½“å‰çº¿ç¨‹å¤„ç†çš„è¡Œç´¢å¼•
  int idx = threadIdx.x + blockDim.x * blockIdx.x;

  // æ­¥éª¤ 1: æ‰¾åˆ°ç¬¬ idx è¡Œçš„æœ€å¤§å€¼ï¼ˆæ•°å€¼ç¨³å®šæ€§ä¼˜åŒ–ï¼‰
  float max_val = -INFINITY;
  for (int i = 0; i < n; i++) {
    if (input[idx * n + i] > max_val) {
      max_val = input[idx * n + i];
    }
  }

  // æ­¥éª¤ 2: è®¡ç®— exp(x_i - max_val) å¹¶ç´¯åŠ 
  // å‡å» max_val å¯ä»¥é˜²æ­¢ exp æº¢å‡ºï¼ŒåŒæ—¶ä¸æ”¹å˜ softmax çš„ç»“æœ
  float sum = 0.f;
  for (int i = 0; i < n; i++) {
    output[idx * n + i] = expf(input[idx * n + i] - max_val);
    sum += output[idx * n + i];
  }

  // æ­¥éª¤ 3: å½’ä¸€åŒ–ï¼Œä½¿å¾—æ¯è¡Œå’Œä¸º 1
  // output[i] = exp(x_i - max) / Î£_j exp(x_j - max)
  for (int i = 0; i < n; i++) {
    output[idx * n + i] /= sum;
  }
}

// -------------------------------
// Helper: Read from .bin file
// -------------------------------
bool read_bin(const char *filename, float *h_data, size_t num_elements) {
  std::ifstream file(filename, std::ios::binary);
  if (!file) {
    printf("âŒ Failed to open %s\n", filename);
    return false;
  }
  file.read((char *)h_data, num_elements * sizeof(float));
  if (!file) {
    printf("âŒ Failed to read data from %s\n", filename);
    file.close();
    return false;
  }
  file.close();
  printf("âœ… Loaded %s (%zu elements)\n", filename, num_elements);
  return true;
}

// -------------------------------
// Helper: Write to .bin file
// -------------------------------
bool write_bin(const char *filename, const float *h_data, size_t num_elements) {
  std::ofstream file(filename, std::ios::binary);
  if (!file) {
    printf("âŒ Failed to create %s\n", filename);
    return false;
  }
  file.write((const char *)h_data, num_elements * sizeof(float));
  file.close();
  printf("âœ… Saved %s (%zu elements)\n", filename, num_elements);
  return true;
}

/**
 * è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ CUDA å®ç°
 *
 * å®ç°å…¬å¼ï¼šAttention(Q, K, V) = softmax(QK^T / âˆšd_k) V
 *
 * è®¡ç®—æµç¨‹ï¼š
 * ==========
 * 1. è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ï¼šS = QK^T / âˆšn
 *    - è¾“å…¥ï¼šQ [m, n], K [m, n]
 *    - è¾“å‡ºï¼šS [m, m]
 *    - ç¼©æ”¾å› å­ï¼š1 / âˆšnï¼ˆé˜²æ­¢ç‚¹ç§¯å€¼è¿‡å¤§ï¼‰
 *
 * 2. Softmax å½’ä¸€åŒ–ï¼šP = softmax(S)
 *    - è¾“å…¥ï¼šS [m, m]
 *    - è¾“å‡ºï¼šP [m, m]ï¼ˆæ¯è¡Œå’Œä¸º 1ï¼‰
 *
 * 3. åŠ æƒæ±‚å’Œï¼šO = PV
 *    - è¾“å…¥ï¼šP [m, m], V [m, n]
 *    - è¾“å‡ºï¼šO [m, n]
 *
 * çŸ©é˜µç»´åº¦ï¼š
 * ==========
 * - Q, K, V: [m, n]
 *   * m: åºåˆ—é•¿åº¦ï¼ˆtoken æ•°é‡ï¼‰
 *   * n: ç‰¹å¾ç»´åº¦ï¼ˆd_kï¼‰
 * - S (sm_o): [m, m] - æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ
 * - P (sm_o after softmax): [m, m] - æ³¨æ„åŠ›æƒé‡çŸ©é˜µ
 * - O: [m, n] - è¾“å‡ºçŸ©é˜µ
 *
 * @param Q Query çŸ©é˜µï¼Œå½¢çŠ¶ [m, n]ï¼Œè®¾å¤‡ç«¯å†…å­˜
 *          - Q[i, :] è¡¨ç¤ºç¬¬ i ä¸ª token çš„ Query å‘é‡
 * @param K Key çŸ©é˜µï¼Œå½¢çŠ¶ [m, n]ï¼Œè®¾å¤‡ç«¯å†…å­˜
 *          - K[i, :] è¡¨ç¤ºç¬¬ i ä¸ª token çš„ Key å‘é‡
 * @param V Value çŸ©é˜µï¼Œå½¢çŠ¶ [m, n]ï¼Œè®¾å¤‡ç«¯å†…å­˜
 *          - V[i, :] è¡¨ç¤ºç¬¬ i ä¸ª token çš„ Value å‘é‡
 * @param O è¾“å‡ºçŸ©é˜µï¼Œå½¢çŠ¶ [m, n]ï¼Œè®¾å¤‡ç«¯å†…å­˜
 *          - O[i, :] è¡¨ç¤ºç¬¬ i ä¸ª token çš„è¾“å‡ºå‘é‡
 * @param m åºåˆ—é•¿åº¦ï¼ˆtoken æ•°é‡ï¼‰
 * @param n ç‰¹å¾ç»´åº¦ï¼ˆd_kï¼Œå³ key çš„ç»´åº¦ï¼‰
 */
void self_attention_cuda(float *Q, float *K, float *V, float *O, int m, int n) {
  // æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„è¡Œæ•°ï¼ˆblock sizeï¼‰
  // mBlock å¿…é¡»èƒ½æ•´é™¤ mï¼Œç¡®ä¿æ‰€æœ‰è¡Œéƒ½è¢«å¤„ç†
  int mBlock = 2;
  assert(m % mBlock == 0 && "mBlock should align");

  // ç¼©æ”¾å› å­ï¼š1 / âˆšd_k
  // ç”¨äºç¼©æ”¾æ³¨æ„åŠ›åˆ†æ•°ï¼Œé˜²æ­¢ç‚¹ç§¯å€¼è¿‡å¤§å¯¼è‡´ softmax æ¢¯åº¦æ¶ˆå¤±
  float sm_scale = 1.f / sqrtf(static_cast<float>(n));

  // åˆ†é…ä¸´æ—¶å†…å­˜å­˜å‚¨æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ S [m, m]
  float *sm_o;
  cudaMalloc((void **)&sm_o, sizeof(float) * m * m);

  // ========== æ­¥éª¤ 1: è®¡ç®— QK^T / âˆšn ==========
  // è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µï¼šS = QK^T / âˆšn
  // è¾“å…¥ï¼šQ [m, n], K [m, n]
  // è¾“å‡ºï¼šsm_o [m, m]
  // å…¬å¼ï¼šsm_o[i, j] = (Q[i, :] Â· K[j, :]) / âˆšn
  dim3 qk_block(m / mBlock, 1, 1);  // æ¯ä¸ª block å¤„ç† m/mBlock è¡Œ
  naive_nrow_gemm<<<1, qk_block>>>(Q, K, sm_o, sm_scale, 0, m, m, n, mBlock);
  // å‚æ•°è¯´æ˜ï¼š
  //   - Q: å·¦çŸ©é˜µ [m, n]
  //   - K: å³çŸ©é˜µ [m, n]ï¼ˆå®é™…è®¡ç®— K^Tï¼‰
  //   - sm_o: è¾“å‡ºçŸ©é˜µ [m, m]
  //   - sm_scale: ç¼©æ”¾å› å­ 1/âˆšn
  //   - 0: ä¸ç´¯åŠ ï¼Œç›´æ¥è¦†ç›–
  //   - m, m, n: çŸ©é˜µç»´åº¦
  //   - mBlock: æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„è¡Œæ•°
  cudaDeviceSynchronize();
  DEBUG_BLOCK(CUDA_CHECK(cudaGetLastError()); printf("== naive QK ==\n");
              print_device_matrix(sm_o, m, m););

  // ========== æ­¥éª¤ 2: Softmax å½’ä¸€åŒ– ==========
  // å¯¹æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µçš„æ¯ä¸€è¡Œè¿›è¡Œ softmax å½’ä¸€åŒ–
  // è¾“å…¥ï¼šsm_o [m, m]ï¼ˆæ³¨æ„åŠ›åˆ†æ•°ï¼‰
  // è¾“å‡ºï¼šsm_o [m, m]ï¼ˆæ³¨æ„åŠ›æƒé‡ï¼Œæ¯è¡Œå’Œä¸º 1ï¼‰
  // å…¬å¼ï¼šP[i, j] = exp(S[i, j] - max_k S[i, k]) / Î£_k exp(S[i, k] - max_k S[i,
  // k])
  dim3 sm_block(m, 1, 1);  // æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€è¡Œï¼Œå…± m ä¸ªçº¿ç¨‹
  row_softmax<<<1, sm_block>>>(sm_o, sm_o, m);
  // å‚æ•°è¯´æ˜ï¼š
  //   - sm_o: è¾“å…¥å’Œè¾“å‡ºçŸ©é˜µ [m, m]ï¼ˆåŸåœ°æ“ä½œï¼‰
  //   - m: æ¯è¡Œçš„å…ƒç´ æ•°é‡ï¼ˆåˆ—æ•°ï¼‰
  cudaDeviceSynchronize();
  DEBUG_BLOCK(CUDA_CHECK(cudaGetLastError());
              printf("== naive softmax(QK) ==\n");
              print_device_matrix(sm_o, m, m););

  // ========== æ­¥éª¤ 3: è®¡ç®— PV ==========
  // è®¡ç®—æœ€ç»ˆè¾“å‡ºï¼šO = PV
  // è¾“å…¥ï¼šP (sm_o) [m, m], V [m, n]
  // è¾“å‡ºï¼šO [m, n]
  // å…¬å¼ï¼šO[i, j] = Î£_k P[i, k] * V[k, j]
  dim3 qkv_block(m / mBlock, 1, 1);  // æ¯ä¸ª block å¤„ç† m/mBlock è¡Œ
  naive_pv<<<1, qkv_block>>>(sm_o, V, O, m, n, mBlock);
  // å‚æ•°è¯´æ˜ï¼š
  //   - sm_o: æ³¨æ„åŠ›æƒé‡çŸ©é˜µ P [m, m]
  //   - V: Value çŸ©é˜µ [m, n]
  //   - O: è¾“å‡ºçŸ©é˜µ [m, n]
  //   - m, n: çŸ©é˜µç»´åº¦
  //   - mBlock: æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„è¡Œæ•°
  cudaDeviceSynchronize();
  DEBUG_BLOCK(CUDA_CHECK(cudaGetLastError());
              printf("== naive softmax(QK)V ==\n");
              print_device_matrix(O, m, n););

  // é‡Šæ”¾ä¸´æ—¶å†…å­˜
  cudaFree(sm_o);
}

// -------------------------------
// Self-Attention with I/O
// -------------------------------

/**
 * è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å®Œæ•´æµç¨‹ï¼ˆåŒ…å«æ–‡ä»¶ I/Oï¼‰
 *
 * åŠŸèƒ½ï¼š
 *   1. ä»äºŒè¿›åˆ¶æ–‡ä»¶è¯»å– Q, K, V çŸ©é˜µ
 *   2. åœ¨ GPU ä¸Šæ‰§è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—
 *   3. å°†ç»“æœä¿å­˜åˆ°äºŒè¿›åˆ¶æ–‡ä»¶
 *
 * æ•°æ®æµç¨‹ï¼š
 *   ==========
 *   æ–‡ä»¶ â†’ ä¸»æœºå†…å­˜ â†’ è®¾å¤‡å†…å­˜ â†’ GPU è®¡ç®— â†’ è®¾å¤‡å†…å­˜ â†’ ä¸»æœºå†…å­˜ â†’ æ–‡ä»¶
 *
 * çŸ©é˜µç»´åº¦ï¼š
 *   - Q, K, V, O: [m, n]
 *   - m: åºåˆ—é•¿åº¦ï¼ˆtoken æ•°é‡ï¼‰
 *   - n: ç‰¹å¾ç»´åº¦ï¼ˆd_kï¼‰
 *   - num_elements = m * nï¼ˆæ¯ä¸ªçŸ©é˜µçš„å…ƒç´ æ•°é‡ï¼‰
 *
 * @param m åºåˆ—é•¿åº¦ï¼ˆtoken æ•°é‡ï¼‰
 * @param n ç‰¹å¾ç»´åº¦ï¼ˆd_kï¼Œå³ key çš„ç»´åº¦ï¼‰
 *
 * æ–‡ä»¶è·¯å¾„ï¼š
 *   - è¾“å…¥ï¼šQ.bin, K.bin, V.bin
 *   - è¾“å‡ºï¼šO_cuda.bin
 */
void self_attention_with_io(int m, int n) {
  // æ¯ä¸ªçŸ©é˜µçš„å…ƒç´ æ•°é‡
  size_t num_elements = m * n;

  // ========== ä¸»æœºç«¯å†…å­˜åˆ†é… ==========
  // åœ¨ CPU ä¸Šåˆ†é…å†…å­˜ï¼Œç”¨äºå­˜å‚¨è¾“å…¥å’Œè¾“å‡ºæ•°æ®
  float *h_Q = new float[num_elements];  // Query çŸ©é˜µ [m, n]
  float *h_K = new float[num_elements];  // Key çŸ©é˜µ [m, n]
  float *h_V = new float[num_elements];  // Value çŸ©é˜µ [m, n]
  float *h_O = new float[num_elements];  // è¾“å‡ºçŸ©é˜µ [m, n]

  // ========== ä»æ–‡ä»¶è¯»å–è¾“å…¥ ==========
  // ä»äºŒè¿›åˆ¶æ–‡ä»¶è¯»å– Q, K, V çŸ©é˜µ
  read_bin("/home/test_fss/code/cuda_code/course9/Q.bin", h_Q, num_elements);
  read_bin("/home/test_fss/code/cuda_code/course9/K.bin", h_K, num_elements);
  read_bin("/home/test_fss/code/cuda_code/course9/V.bin", h_V, num_elements);

  // ========== è®¾å¤‡ç«¯å†…å­˜åˆ†é… ==========
  // åœ¨ GPU ä¸Šåˆ†é…å†…å­˜ï¼Œç”¨äºå­˜å‚¨è¾“å…¥å’Œè¾“å‡ºæ•°æ®
  float *d_Q, *d_K, *d_V, *d_O;
  CUDA_CHECK(cudaMalloc(&d_Q, num_elements * sizeof(float)));  // Query [m, n]
  CUDA_CHECK(cudaMalloc(&d_K, num_elements * sizeof(float)));  // Key [m, n]
  CUDA_CHECK(cudaMalloc(&d_V, num_elements * sizeof(float)));  // Value [m, n]
  CUDA_CHECK(cudaMalloc(&d_O, num_elements * sizeof(float)));  // è¾“å‡º [m, n]

  // ========== æ•°æ®ä¼ è¾“ï¼šä¸»æœº â†’ è®¾å¤‡ ==========
  // å°†è¾“å…¥æ•°æ®ä» CPU å†…å­˜å¤åˆ¶åˆ° GPU å†…å­˜
  CUDA_CHECK(cudaMemcpy(d_Q, h_Q, num_elements * sizeof(float),
                        cudaMemcpyHostToDevice));
  CUDA_CHECK(cudaMemcpy(d_K, h_K, num_elements * sizeof(float),
                        cudaMemcpyHostToDevice));
  CUDA_CHECK(cudaMemcpy(d_V, h_V, num_elements * sizeof(float),
                        cudaMemcpyHostToDevice));

  // ========== GPU è®¡ç®— ==========
  // åœ¨ GPU ä¸Šæ‰§è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—
  // è®¡ç®—ï¼šO = softmax(QK^T / âˆšn) V
  self_attention_cuda(d_Q, d_K, d_V, d_O, m, n);

  // ========== æ•°æ®ä¼ è¾“ï¼šè®¾å¤‡ â†’ ä¸»æœº ==========
  // å°†è®¡ç®—ç»“æœä» GPU å†…å­˜å¤åˆ¶å› CPU å†…å­˜
  CUDA_CHECK(cudaMemcpy(h_O, d_O, num_elements * sizeof(float),
                        cudaMemcpyDeviceToHost));

  // ========== ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ ==========
  // å°†è¾“å‡ºçŸ©é˜µä¿å­˜åˆ°äºŒè¿›åˆ¶æ–‡ä»¶
  write_bin("/home/test_fss/code/cuda_code/course9/O_cuda.bin", h_O,
            num_elements);

  // ========== æ¸…ç†å†…å­˜ ==========
  // é‡Šæ”¾ä¸»æœºç«¯å†…å­˜
  delete[] h_Q;
  delete[] h_K;
  delete[] h_V;
  delete[] h_O;
  // é‡Šæ”¾è®¾å¤‡ç«¯å†…å­˜
  cudaFree(d_Q);
  cudaFree(d_K);
  cudaFree(d_V);
  cudaFree(d_O);

  printf("ğŸ‰ Self-attention completed. Output saved to O_cuda.bin\n");
}

// -------------------------------
// Entry point
// -------------------------------

/**
 * ä¸»å‡½æ•°ï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å…¥å£ç‚¹
 *
 * é…ç½®å‚æ•°ï¼š
 *   - m = 64: åºåˆ—é•¿åº¦ï¼ˆtoken æ•°é‡ï¼‰
 *     * è¡¨ç¤ºè¾“å…¥åºåˆ—æœ‰ 64 ä¸ª token
 *   - n = 128: ç‰¹å¾ç»´åº¦ï¼ˆd_kï¼‰
 *     * è¡¨ç¤ºæ¯ä¸ª token çš„ç‰¹å¾å‘é‡ç»´åº¦ä¸º 128
 *
 * çŸ©é˜µç»´åº¦ï¼š
 *   - Q, K, V: [64, 128]
 *   - QK^T: [64, 64]
 *   - O: [64, 128]
 *
 * è®¡ç®—æµç¨‹ï¼š
 *   1. ä»æ–‡ä»¶è¯»å– Q, K, V çŸ©é˜µ
 *   2. åœ¨ GPU ä¸Šè®¡ç®—ï¼šO = softmax(QK^T / âˆš128) V
 *   3. å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
 */
int main() {
  // åºåˆ—é•¿åº¦ï¼š64 ä¸ª token
  const int m = 64;
  // ç‰¹å¾ç»´åº¦ï¼šæ¯ä¸ª token çš„ç‰¹å¾å‘é‡ç»´åº¦ä¸º 128
  const int n = 128;

  printf("ğŸš€ Running self-attention for m=%d, n=%d\n", m, n);
  // æ‰§è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—
  // è®¡ç®—ï¼šAttention(Q, K, V) = softmax(QK^T / âˆšn) V
  self_attention_with_io(m, n);

  return 0;
}
